COMMENT

Ethics of quantification: illumination, obfuscation
and performative legitimation

Siddharth Sareen 1,2*, Andrea Saltelli 2 & Kjetil Rommetveit2

ABSTRACT
The increasing use of quantification in all spheres of society is paralleled by the
rise of digitalisation. These intertwining developments not only revolutionise
data treatment, but also its societal effects. On the one hand, they have wonderfully
enabling societal effects. On the other hand, they give rise to complex
ethical dilemmas that motivate this call for an ethics of quantification. The
central claim of this Comment is that quantification necessarily has two faces:
illumination and obfuscation. Aspects that can be socially legitimated are illuminated,
while those that cannot be so legitimated are obfuscated. This obfuscation
poses ethical problems, hence its effects require rigorous analysis. Three
ontologies of quantification are delineated to enable such examination: (i) as the
disembodied practice of data processing in the ‘ether’—this foregrounds elements
of big data and artificial intelligence; (ii) as the situated practice and
effects of quantification within societal contexts—this attends to governing
subjects through numbers; and (iii) as increasingly incorporated in physical
reality—this focuses on governmentality of behaviours and behavioural change
as mediated through everyday objects through an ‘Internet of Things’. Drawing
on scholarship from the emerging sociology of quantification, the ethics of
quantification is defined as the iterative illumination of obfuscation in legitimation
by quantification. This is key for ensuring contextually desirable illuminating
functions of quantification in all three ontologies.

https://doi.org/10.1057/s41599-020-0396-5 OPEN

1Department of Geography, University of Bergen, Bergen, Norway. 2 Centre for the Study of the Sciences and the Humanities, University of Bergen,
Bergen, Norway. *email: Siddharth.Sareen@uib.no

PALGRAVE COMMUNICATIONS | (2020) 6:20 | https://doi.org/10.1057/s41599-020-0396-5 | www.nature.com/palcomms 1

1234567890():,;
Introduction: The case for an ethics of quantification
Entering the 2020s, we live in an era marked by the ubiquity
of quantification. Variants of the adage “not all that counts
can be counted, but what is counted counts” have proliferated.
Metrics accompany many of us in a bewildering array of
activities. These range from the formal (giving satisfaction ratings
after a meeting or hotel stay, submitting credit ratings to take on a
mortgage, checking domestic electricity consumption when paying
monthly utility bills) to the informal and everyday (tracking
one’s daily run speed and distance, reviewing new beers drunk at
a bar on a smartphone application to notch up experience points,
monitoring one’s sleep patterns using a smart watch). They can
be distant (tapping a smiley button to rate the experience of going
through airport security protocols) or intimate (registering biometrics
such as one’s fingerprints to go through immigration
border controls). They can be voluntary (a citizen filling out a
national survey to feed their household characteristics into a
demographics database) or coercive (public surveillance linked
with a facial recognition database to fine jaywalkers). They can be
clearly signposted (traffic counters along bicycle routes) or
stealthy (sensors like WiFi signals that collect information such as
purchase histories from proximate smartphones for efficient realtime
targeted advertising at passers-by in public spaces). They can
result in the production of a tangible number (e.g., an indicator, a
rating) or decision, where the number crunching is out of sight,
e.g., in facial recognition (O’Neil, 2016). The data, data points and
pieces of information are increasingly incorporated into largescale
information infrastructures operating across policy and
everyday domains, as well as across territorial and sovereign
borders. Streams of metrics along these spectra are constantly
collected, processed and used in ways that we increasingly take
for granted.
This unprecedented generation of data to metricise innumerable
aspects of everyday life is paralleled by unprecedented
computing power and technological sophistication to process
such vast quantities of data (Savage, 2013). Data is organised into
an assortment of data points, information, statistics and metrics
by a wide variety of actors who deploy them for such versatile
purposes that their direct and indirect effects are far from clear.
What is resoundingly clear, however, is that these effects have
significant political and ethical implications. Quantification of the
self, combined with digitalisation on steroids, has systemic effects;
it reconfigures intimate matters like healthcare not only for
individuals but as a vital socio-economic sector acted upon at the
aggregate level (Lupton, 2016). Prior distinctions between facts
and values, so central to modern western societies, collapse in
streams of raw data feeding algorithms that learn and reason, and
connect data from unexpected sites and sources. The intermeshing
of big data and algorithms increasingly blurs distinctions
between different forms and indeed purposes of quantification.
They cut across the infinitely small (i.e., nano-molecules) and the
infinitely big (Planet Earth), and apply to seemingly any process,
from education to traffic management to biomedical research.
Berman and Hirschman (2018) enquire: “What qualities are
specific to rankings, or indicators, or models, or algorithms?”
There is appetite to scrutinise quantification for perceived
misuse of existing methodologies. For instance, the convulsions of
significance testing in statistics have received wide attention
(Amrhein et al., 2019), whereas mathematical modelling is a field
with severe uncharted problems (Saltelli, 2019). Algorithms pose
the risk of non-transparent, oft-proprietary tools used in
decision-making and for policy support. Much quantification
carries the conundrum that, without representing context and
purpose of production, numbers can obfuscate as much as illuminate.
Yet measurements generate traction for issues, hence
acting within society often requires an appreciation of and

entanglement with data politics (Bigo et al., 2019). The time is
thus ripe for an ethics of quantification (Saltelli, 2020).

Ethical dilemmas in the societal legitimation of quantification
As Dencik et al. (2019) point out, the way data and society act
upon each other is changing the meaning of justice, specifically
data justice for society. Quantification is performative; it serves a
legitimating function (Porter, 1996) because it can in principle
illuminate and make hitherto intangible things commensurable.
Ever increasing sophistication in the metricisation of data has
reconstituted fields like global health in deep entanglement with
financial markets and data management systems, quantifying
attributes of bodies and populations in ways that impact the
distribution of certainty and risk in healthcare (Adams, 2016).
This raises the question of what basis actors use to claim commensurability.
As a case in point, the Stat-Activisme movement
in France aims to ‘fight against’ and ‘fight with’ numbers; it uses
‘statistical judo’ to expose the vacuity of existing metrics, and to
statistically identify exclusion and neglect (Bruno et al., 2014).
This can be read as an attempt to open the ‘black box’ of quantification
and challenge its predominant modality of legitimation
in terms of simply ‘more data’ or ‘more efficiency’ or ‘improved
competitiveness’.
An even more radical critique is offered by the French jurist
Alain Supiot (2007), for whom the neoliberal market ideology has
embraced quantification, so as to implement a sort of cybernetic,
homoeostatic, horizontal society. This replaces the previous
Fordist and Taylorist mechanical models. In the new model, the
labour force is constantly mobilised though management by
objectives. Here, numbers replace laws to create a world of dystopian
injustice and dysfunction, where the only solution for
individuals is to revert to a system of allegiance to the strongest
actors (Supiot, 2007). This happens even as many (or most) of
today’s societal problems are of a nature that cannot be quantified,
such as the consequences of species extinction, the impacts
of a major terrorist attack, or the possible consequences of artificial
intelligence (AI) systems that operate critical infrastructures
going out of control. Neoliberal regimes of innovation and governance
are premised on entrepreneurs actively embracing the incalculability
and subjective perceptions of risk and uncertainty,
following the epistemic principle to ‘run-it-and-see-what-happens’
(Rommetveit and Wynne, 2017) or Facebook’s celebrated—
or execrated—‘move fast and break things’.
Governance regimes that rely on quantification invariably use
it to legitimate decisions and activities, such as resource allocation,
and highlight that which is socially legitimatable (we define
legitimatable to mean ‘that which can be legitimated’). Yet where
there is scope for interpretation, there is room for strategic
manoeuvre. Hence there is a risk that things that are not socially
legitimatable may be hidden, for instance when citizens are not
able to register with a biometric system, such as Aadhaar in India,
thus becoming invisible to and being made invisible by the biometricising
state (Dandurand, 2019; Wevers, 2018). When such
sleight of hand—even if unwittingly executed by a benevolent
actor—is not detected and challenged, the effect of an impulse to
quantify can be to distort what it quantifies and why.
For instance, any national government asking all its citizens to
embed a chip in their wrist to share their real-time location is
likely to be met with resistance despite assurances of maintaining
anonymity in its use of data; yet a majority of citizens in most
Western democracies today carry a smartphone on their person
and consent to sharing their location with a number of applications
owned by multinational private corporations on an everyday
basis, most commonly to facilitate their live use of local maps.

COMMENT PALGRAVE COMMUNICATIONS | https://doi.org/10.1057/s41599-020-0396-5

2 PALGRAVE COMMUNICATIONS | (2020) 6:20 | https://doi.org/10.1057/s41599-020-0396-5 | www.nature.com/palcomms
This ability to track location is routinely combined with a great
deal of other background information (often by third parties) and
constitutes a remarkably potent resource for commercial (and
potentially other) uses within surveillance capitalism. Users
consent to this, not merely to being users, but effectively also the
products on sale, when they install smartphone applications. But
the users are rarely if ever presented with a comprehensive and
comprehensible explanation of such uses, which is relegated to
the fine-print of the terms and conditions that apply. We want to
use mapping services, but forcibly we also end up consenting to
surveillance. The socially legitimatable use is highlighted; not
socially legitimatable uses are obfuscated.
Markham et al. (2018) warn that a grand narrative around data
analytics that accords truth value to knowledge based on objectivity
claims and sheer volume can obscure processual human
decisions. These authors forge ways to work with the awareness
that, as algorithmic governance becomes ubiquitous, an
accountability crisis is unfolding in the way societal interventions
are deployed, based as they are on incomplete assumptions about
big data. Not only do actors who perform algorithmic governance
selectively play up its socially legitimatable uses, over time this
mode of governance acts on society to expand the ambit of what
can be socially legitimated. In Europe and globally, this is to some
extent becoming recognised, for instance in up-scaled data protection
frameworks, ethical guidelines for AI, and ‘ethically
aligned designs’ of autonomous systems (IEEE, 2018). Yet, the
question remains to what extent and at what speed such governance
frameworks can remedy the democratic and regulatory
deficits.
Never as today have the media been so determinant in accelerating
the transactions taking place between science, technology,
society and law (Saltelli and Boulager, 2020). For these authors,
who look at the present with the lenses of Niklas Luhmann’s
social system theory, we are witnessing one social system—the
media—irritating other systems, such as science, policy and
technology up to the point of incapacitating some of the internal
(autopoietic) functions of the systems themselves. When social
media networks first came into being, few could have imagined
sharing as much of their personal information online as many
people do now without much consideration. This iterative trend
feeds a quantification machine that in turn changes what personal
means, and even who a person is. At such a juncture of flux, Hesse
et al. (2019) think through the continuing relevance of qualitative
data. They advocate for methodological diversity, contextualised
and inclusive research, nuanced discussion of ethical dilemmas
that transcend legality, translocal and transdisciplinary conversations,
and responsible research and data infrastructures.
Research must now respond to the need to examine at depth
the issues flagged by the forays discussed above. We frame this
collective task as showing that analysis of the ethics of quantification
can draw out, in various ways, how quantification obfuscates
to legitimate. Understanding how such obfuscation happens
and is performed can equip us with the means to confront it in
practice, and to support the illuminating function of quantification
in context-specific ways.
Whilst the present juncture intensifies the effect of quantification,
our claim holds true at all times. The introduction of
statistics and data collection on demographics from the mid-18th
century onwards (Hacking, 1990) gradually eclipsed other ways of
knowing and came to structure practices like national budgets,
enabling key instruments of state power. While such quantification
enhanced abilities for centralised planning, by the same
token it eroded power at local scales where local knowledge was
not, and could not be, quantified in national databases, but
informed decisions through its everyday embodiment in the
bodies of local planners. To take another noted example: John

Snow quantified and spatially mapped London’s cholera deaths to
reveal that the epidemic was linked to water from specific wells, a
novel methodology at the time whose success led to wide
acceptance. Laudable in itself, this instance is not innocent; it
could have been used as a basis to avoid investing in preventive
measures to safeguard against contamination in less affluent
areas, citing the methodology as a means to spatially limit an
epidemic in case it occurred there. The Aadhaar example is a case
in point of institutionalising non-innocent metrics. Despite clear
evidence of limited data infrastructure to support reliable use of
biometrics for benchmarking, and consequent risks of misdistribution
in public schemes (Dandurand, 2019) or exclusion of
marginalised groups like hard-working labourers with “Lost fingers,
damaged fingertips, and rubbed‐off skin contours” that
make fingerprints unreadable (Rao, 2013, p. 74), the programme
is backed by the state at the cost of vulnerable people (Drèze et al.,
2017).
A listing of similar examples of non-innocent use of quantification
would invoke a rich body of literature related to the misuse
of metrics (Muller, 2018), algorithms (O’Neil, 2016) and statistical
and mathematical modelling (Saltelli, 2020). Take the role of
numbers produced in the financial centres of computation and
held responsible for the onset of the most recent recession
(Porter, 2012; Wilmott and Orrell, 2017; Ravetz, 2008). Bold
intellectual manoeuvres such as those of Steven Pinker (2018),
that deluge the reader with a profusion of numbers and graphs to
argue that humankind has never had it so good, that inequality is
non-existent or irrelevant, and that racism is receding, may also
be classified as non-innocent (Lent, 2018; Riskin, 2019). In this
specific example, Pinker adopts an aggressive stance against the
purported enemies of Enlightenment—a broad category spanning
from Nietzsche to Pope Francis via the Frankfurt School, the New
York Times, and the discipline of Science Studies. In doing so,
Pinker mobilises genuine and quantified instances of progress to
advance the author’s political stance and worldview via the
selective use of measures. As discussed in Saltelli (2020), a heterogeneous
community increasingly perceives and indicts
quantification as instrumental to domination, including technologists
(Lanier, 2006), jurists (Supiot, 2007) and economists
(Zuboff, 2019).
Thus, any exercise of quantification demands an ethics to
situate it within a given social context, not least because quantification
acts in reflexive relation to the object and the environment
that is quantified (Sareen et al., 2020; Saltelli, 2020).

A definition and three ontologies for the ethics of
quantification
Whether as citizens or as users, our bodies and lives are governed
as subjects, yet within the new data economy we also occur as
mere data sources. The expanding creep of quantification subtracts
decisional space from the governed subjects to governing
ones, reducing the space for democratic objections, which would
instead question the desirability of the new practices. This new
brand of quantification banks on the social legitimacy of the
models it deploys as proxies for reality. Complex as these are,
these artefacts of quantification are simplified representations of
reality and thus liable to be flawed. Their defensibility is a sleight
of hand justified by pragmatic necessity. Practicing an ethics of
quantification entails constant awareness of its intrinsic nature as
a legitimation device that must be subjected to scrutiny and held
to account by an active societal movement of resistance (Bruno
et al., 2014; Saltelli, 2020). We can thus define an ethics of
quantification as the iterative illumination of obfuscation in
legitimation by quantification. Only then can quantification perform
its illuminating function.

PALGRAVE COMMUNICATIONS | https://doi.org/10.1057/s41599-020-0396-5 COMMENT

PALGRAVE COMMUNICATIONS | (2020) 6:20 | https://doi.org/10.1057/s41599-020-0396-5 | www.nature.com/palcomms 3
We heuristically distinguish between and address three ontologies
of quantification:

● as the disembodied practice of data processing in the ‘ether’; ● as the situated practice and effects of quantification within
societal contexts; and ● as increasingly incorporated in physical reality itself (through
the ubiquitous use of sensors, radio frequency identification
and the like).
The first ontology foregrounds elements of big data and AI; the
second ontology attends to governing subjects through numbers;
and the third introduces governmentality of behaviours and
behavioural change as mediated through everyday objects and
things through an ‘Internet of Things’.
Foregrounding big data, AI and the increasing automation of
tasks—which combine so that computing can feed off of vast
quantities of societally generated data using trial and error, commonly
referred to as machine learning—focuses our attention on
the ethical concerns implicated in the practice of quantification
itself. Life in the 2020s is permeated by advertisements, news feeds,
information access, personal search histories, social media cookies
and cloud-based personal data repositories. These artefacts render
big data and AI pervasive to a degree that impacts the qualitative
implications of quantification. By tapping into, acting upon and
becoming imbricated into everyday infrastructures, quantification
becomes co-constitutive of everyday life. It becomes an adaptive
structuring force that interplays with institutional structures and
individual agency (Supiot, 2007). Addressing how AI impacts
cognitive capacity and privacy, and what is lost and gained in the
process, is thus inextricably linked with the ethics of quantification.
The sets of big data that feed AI are generated in societal
contexts that feature deeply entrenched inequities and injustices.
There is thus a risk of reinforcing effects, reifying tendencies and
rigidifying divisions through vicious cycles. Hence, we are particularly
interested in scrutinising how AI differs from societal traits
such as prioritising and privileging ‘similar others’, and whether it
reproduces or exacerbates them. A thorough understanding of
these mechanisms has implications for standards and regulations
around expanding AI and big data use.
Attending to the situated practice and effects of quantification
within societal contexts and infrastructures places the focus on
sociological and socio-material aspects of the ethics of quantification—which
calls for the combined efforts of technologists,
sociologists, jurists, statisticians and data scientists. This requires
probing how citizens interact with quantification and become
quantified subjects who are governed through numbers in vital
aspects of their lives in incredibly powerful ways. It also requires
tracing the networks and practices of increasingly coordinated
transnational infrastructures that underpin the new ‘data economy’.
The modalities of quantification are typically decided at
higher levels of decision-making than the individual level that is
being quantified through data extraction, posing the question of
whose seeing is enabled and empowered, and who is merely
‘being seen’ without the required mechanisms for checks and
balances on the watchers (Sareen and Rommetveit, 2019). Major
decisions often take place in a socio-spatially centralised manner,
with little room for representation of individual concerns and
preferences by the citizens they affect. There are thus elements of
uneven scalar effects (in terms of both hierarchical levels and
spatial scales) to consider in relation to modalities such as what is
quantified about citizens as subjects and about everyday phenomena
like consumption, metrical performance, environmental
interaction and death.
We discern a need to articulate the relationship between
measurement and subjecthood in order to understand the ethical
implications of how quantification acts on its subjects. This

means recognising as inherently political the very act of choosing
quantifiable proxy variables that render particular characteristics
of messy reality commensurable and then serve to represent
them. This movement is not new, and has precedents in the
decadal fight of sociologists and ecologists against the numerification
of everything, whereby both society and the environment
can be seen as subject to neat systems of prediction and control
(Pereira and Funtowicz, 2015; Stirling, 2019, 2008). Whether it is
representative or not, quantification provides an evidence base to
make claims about how things are. In doing so, it impacts both
public understandings and societal commitments to particular
configurations of resource allocation. Unpacking its evolving
modalities has thus become critical to engagement with the
embodied socio-material conditions of life in the 2020s.

Received: 9 December 2019; Accepted: 17 January 2020;

References
Adams V (2016) Metrics: what counts in global health. Duke University Press
Amrhein V, Greenland S, McShane B (2019) Scientists rise up against statistical
significance. Nature 567(7748):305–307
Berman EP, Hirschman D (2018) The sociology of quantification: where are we
now? Contemp Sociol 47(3):257–266
Bigo D, Isin E, Ruppert E (2019) Data politics: worlds, subjects, rights. Routledge,
London
Bruno I, Didier E, Prévieux J (2014) Stat-Activisme. Comment Lutter Avec Des
Nombres. Zones, La Découverte, Paris
Dandurand G (2019) When biopolitics turn digital: transparency, corruption, and
erasures from the infrastructure of rationing in Delhi. Political Leg Anthropol
Rev 42(2):268–282
Dencik L, Hintz A, Redden J, Treré E (2019) Exploring data justice: conceptions,
applications and directions. Inf Commun Soc 22(7):873–881
Drèze J, Khalid N, Khera R, Somanchi A (2017) Aadhaar and food security in
Jharkhand. Econ Political Wkly 52(50):51
Hacking I (1990) The taming of chance (Cambridge University Press)
Hesse A, Glenna L, Hinrichs C, Chiles R, Sachs C (2019) Qualitative research ethics
in the big data era. Am Behav Sci 63(5):560–583
IEEE (2018) Ethically aligned design: a vision for prioritizing human well-being
with autonomous and intelligent systems. The IEEE Global Initiative on
Ethics of Autonomous and Intelligent Systems
Lanier J (2006) Who owns the future? Penguin Books
Lent J (2018) Steven Pinker’s ideas are fatally flawed. These eight graphs show why.
open Democracy
Lupton D (2016) The quantified self. John Wiley & Sons
Markham AN, Tiidenberg K, Herman A (2018) Ethics as methods: doing ethics in
the era of big data research—Introduction. Soc Media+ Soc 4
(3):2056305118784502
Muller J (2018) The tyranny of metrics. Princeton University Press
O’Neil C (2016) Weapons of math destruction: how big data increases inequality
and threatens democracy. Random House Publishing Group
Pereira A, Funtowicz S (2015) Science, philosophy and sustainability: the end of the
Cartesian dream. Routledge
Pinker S (2018) Enlightenment now: the case for reason, science, humanism, and
progress. Random House
Porter T (1996) Trust in numbers: the pursuit of objectivity in science and public
life. Princeton University Press
Porter T (2012) Funny numbers. Cult Unbound 4:585–598
Rao U (2013) Biometric marginality: UID and the shaping of homeless identities in
the city. Econ Political Wkly 48(13):71–77
Ravetz J (2008) Faith and reason in the mathematics of the credit crunch. Oxford
Magazine
Riskin J (2019) Pinker’s Pollyannish philosophy and its perfidious politics. Review
of Books, Los Angeles
Rommetveit K, Wynne B (2017) Technoscience, imagined publics and public
imaginations. Public Underst Sci 26(2):133–147
Saltelli A (2019) A short comment on statistical versus mathematical modelling.
Nat Commun 10:3870
Saltelli A (2020) Ethics quantification or quantification ethics? Futures 116:102509
Saltelli A, Boulanger P (2020) Technoscience, policy and the new media. Nexus or
vortex? Futures 115:102491
Sareen S, Rommetveit K (2019) Smart gridlock? Challenging hegemonic framings
of mitigation solutions and scalability. Environ Res Lett 14(7):075004

COMMENT PALGRAVE COMMUNICATIONS | https://doi.org/10.1057/s41599-020-0396-5

4 PALGRAVE COMMUNICATIONS | (2020) 6:20 | https://doi.org/10.1057/s41599-020-0396-5 | www.nature.com/palcomms
Sareen S, Thomson H, Tirado Herrero S, Gouveia JP, Lippert I, Lis A (2020)
European energy poverty metrics: scales, prospects and limits. Glob Trans
2:26–36
Stirling A (2019) How politics closes down uncertainty—STEPS Centre. STEPS
Centre
Stirling A (2008) “Opening up” and “closing down” power, participation, and
pluralism in the social appraisal of technology. Sci Technol Hum Values 33
(2):262–294
Supiot A (2007) Governance by numbers: the making of a legal model of allegiance.
Oxford University Press
Savage M (2013) The ‘social life of methods’: a critical introduction. Theory Cult
Soc 30(4):3–21
Wevers R (2018) Unmasking biometrics’ biases: facing gender, race, class and
ability in biometric data collection. J Media Hist 21(2):89–105
Wilmott P, Orrell D (2017) The money formula. Wiley & Sons
Zuboff S (2019) The age of surveillance capitalism: the fight for a human future at
the new frontier of power. PublicAffairs

Acknowledgements
The authors are grateful for support from the Centre for the Study of the Sciences and the
Humanities, University of Bergen, which made this contribution and collaboration
possible.

Competing interests
The authors declare no competing interests.

Additional information
Correspondence and requests for materials should be addressed to S.S.

Reprints and permission information is available at http://www.nature.com/reprints

Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in
published maps and institutional affiliations.

Open Access This article is licensed under a Creative Commons
Attribution 4.0 International License, which permits use, sharing,
adaptation, distribution and reproduction in any medium or format, as long as you give
appropriate credit to the original author(s) and the source, provide a link to the Creative
Commons license, and indicate if changes were made. The images or other third party
material in this article are included in the article’s Creative Commons license, unless
indicated otherwise in a credit line to the material. If material is not included in the
article’s Creative Commons license and your intended use is not permitted by statutory
regulation or exceeds the permitted use, you will need to obtain permission directly from
the copyright holder. To view a copy of this license, visit http://creativecommons.org/
licenses/by/4.0/.

© The Author(s) 2020

PALGRAVE COMMUNICATIONS | https://doi.org/10.1057/s41599-020-0396-5 COMMENT

PALGRAVE COMMUNICATIONS | (2020) 6:20 | https://doi.org/10.1057/s41599-020-0396-5 | www.nature.com/palcomms 5